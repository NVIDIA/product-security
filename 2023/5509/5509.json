{
    "document": {
        "aggregate_severity": {
            "namespace": "https://www.first.org/cvss/v4.0/specification-document#Qualitative-Severity-Rating-Scale",
            "text": "HIGH"
        },
        "category": "csaf_security_advisory",
        "csaf_version": "2.0",
        "distribution": {
            "text": "Copyright \u00a9 2025 NVIDIA Corporation. All rights reserved.",
            "tlp": {
                "label": "WHITE",
                "url": "https://www.first.org/tlp/"
            }
        },
        "lang": "en",
        "notes": [
            {
                "category": "summary",
                "text": "NVIDIA has released a software update for NVIDIA Triton Inference Server to address the issue disclosed in this bulletin. This issue affects only nondefault deployments that enable dynamic model loading through the model control APIs by using the command line option --model-control explicit. Deployments that use default settings are not affected. To protect your system, install the latest release from the <a href=\"https://github.com/triton-inference-server/server/releases\">Triton Inference Server</a> Releases page on GitHub, and view the <a href=\"https://github.com/triton-inference-server/server/blob/main/docs/customization_guide/deploy.md\">Secure Deployment Considerations Guide</a>.",
                "title": "Summary"
            },
            {
                "category": "legal_disclaimer",
                "text": "ALL NVIDIA INFORMATION, DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, \"MATERIALS\") ARE BEING PROVIDED \"AS IS.\" NVIDIA MAKES NO WARRANTIES, EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND ALL EXPRESS OR IMPLIED CONDITIONS, REPRESENTATIONS AND WARRANTIES, INCLUDING ANY IMPLIED WARRANTY OR CONDITION OF TITLE, MERCHANTABILITY, SATISFACTORY QUALITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT, ARE HEREBY EXCLUDED TO THE MAXIMUM EXTENT PERMITTED BY LAW.\n\nInformation is believed to be accurate and reliable at the time it is furnished. However, NVIDIA Corporation assumes no responsibility for the consequences of use of such information or for any infringement of patents or other rights of third parties that may result from its use. No license is granted by implication or otherwise under any patent or patent rights of NVIDIA Corporation. Specifications mentioned in this publication are subject to change without notice. This publication supersedes and replaces all information previously supplied. NVIDIA Corporation products are not authorized for use as critical components in life support devices or systems without express written approval of NVIDIA Corporation.",
                "title": "Terms of Use"
            },
            {
                "category": "details",
                "text": "Users deploying NVIDIA Triton Inference Server in production settings should follow the <a href=\"https://github.com/triton-inference-server/server/blob/main/docs/customization_guide/deploy.md\">Secure Deployment Considerations Guide</a> and ensure that logging and shared memory APIs are protected for use by authorized users.",
                "title": "Security Update Notes"
            },
            {
                "category": "details",
                "text": "<ul><li>This vulnerability affects only nondefault deployments that enable dynamic model loading through the model control APIs by using the command line option --model-control explicit. Deployments that use default settings are not affected.<br></li></ul><div><br></div><div>The following items were made available in the development branch on November 10, 2023 and are available in the release branch on December 4, 2023.<br></div><div><ul><li>Updated software that behaves as follows:<br></li><li>Provides the ability to restrict the HTTP endpoint of the model load API<br></li><li>Prevents the model load API from accessing directories outside the model directory<br></li><li>A <a href=\"https://github.com/triton-inference-server/server/blob/main/docs/customization_guide/deploy.md\">Secure Deployment Considerations Guide</a>  intended to provide some key points and best practices that users deploying Triton based solutions should consider.</li></ul></div><div><br></div><div><br></div><div><br></div><div><br></div>",
                "title": "Bulletin Notes"
            },
            {
                "category": "details",
                "text": "TB-NA",
                "title": "Part Number"
            },
            {
                "category": "details",
                "text": "NA",
                "title": "Product Information Delivery"
            },
            {
                "category": "details",
                "text": "23:Triton",
                "title": "Product Team"
            },
            {
                "category": "details",
                "text": "false",
                "title": "Contains Firmware"
            }
        ],
        "publisher": {
            "category": "vendor",
            "contact_details": "https://www.nvidia.com/security/report-vulnerability/",
            "issuing_authority": "NVIDIA Product Security is responsible for vulnerability handling across all NVIDIA products and services.",
            "name": "NVIDIA Product Security",
            "namespace": "https://www.nvidia.com/security"
        },
        "title": "Security Bulletin: NVIDIA Triton Inference Server - December 2023",
        "tracking": {
            "current_release_date": "2023-12-19T00:00:00Z",
            "generator": {
                "date": "2023-12-19T00:00:00Z",
                "engine": {
                    "name": "NVIDIA PSIRT",
                    "version": "1.0.0"
                }
            },
            "id": "5509",
            "initial_release_date": "2023-12-19T00:00:00Z",
            "revision_history": [
                {
                    "date": "2023-12-19T00:00:00Z",
                    "number": "1.0.0",
                    "summary": "Initial Release"
                }
            ],
            "status": "final",
            "version": "1.0.0"
        }
    },
    "product_tree": {
        "branches": [
            {
                "branches": [
                    {
                        "branches": [
                            {
                                "category": "product_name",
                                "name": "Triton Inference Server",
                                "product": {
                                    "name": "Triton Inference Server",
                                    "product_id": "windows_linux_triton_inference_server",
                                    "product_identification_helper": {
                                        "cpe": "cpe:2.3:a:nvidia:triton_inference_server:*:*:*:*:*:*:*:*"
                                    }
                                }
                            }
                        ],
                        "category": "product_family",
                        "name": "NVIDIA Product Family"
                    },
                    {
                        "branches": [
                            {
                                "category": "product_version",
                                "name": "Triton Inference Server",
                                "product": {
                                    "name": "All versions prior to 2.40",
                                    "product_id": "windows_linux_triton_inference_server_all_versions_prior_to_2_40",
                                    "product_identification_helper": {
                                        "cpe": "cpe:2.3:a:nvidia:triton_inference_server:all_versions_prior_to_2_40:*:*:*:*:*:*:*"
                                    }
                                }
                            },
                            {
                                "category": "product_version",
                                "name": "Triton Inference Server",
                                "product": {
                                    "name": "2.40",
                                    "product_id": "windows_linux_triton_inference_server_2_40",
                                    "product_identification_helper": {
                                        "cpe": "cpe:2.3:a:nvidia:triton_inference_server:2_40:*:*:*:*:*:*:*"
                                    }
                                }
                            }
                        ],
                        "category": "architecture",
                        "name": "Windows, Linux"
                    }
                ],
                "category": "vendor",
                "name": "NVIDIA"
            }
        ]
    },
    "vulnerabilities": [
        {
            "acknowledgments": [
                {
                    "names": [
                        "l1k3beef @ tencent-zhuquelab"
                    ]
                }
            ],
            "cve": "CVE-2023-31036",
            "cwe": {
                "id": "CWE-23",
                "name": "Relative Path Traversal"
            },
            "notes": [
                {
                    "category": "summary",
                    "text": "NVIDIA Triton Inference Server for Linux and Windows contains a vulnerability where, when it is launched with the non-default command line option --model-control explicit, an attacker may use the model load API to cause a relative path traversal. A successful exploit of this vulnerability may lead to code execution, denial of service, escalation of privileges, information disclosure, and data tampering.",
                    "title": "Vulnerability description"
                },
                {
                    "category": "details",
                    "text": "Code Execution, Denial of Service, Escalation of Privileges, Information Disclosure, Data Tampering",
                    "title": "Impacts"
                },
                {
                    "category": "details",
                    "text": "4328899",
                    "title": "defect"
                }
            ],
            "product_status": {
                "fixed": [
                    "windows_linux_triton_inference_server_2_40"
                ],
                "known_affected": [
                    "windows_linux_triton_inference_server_all_versions_prior_to_2_40"
                ]
            },
            "references": [
                {
                    "category": "self",
                    "summary": "NVD",
                    "url": "https://nvd.nist.gov/vuln/detail/CVE-2023-31036"
                },
                {
                    "category": "self",
                    "summary": "Mitre",
                    "url": "https://www.cve.org/CVERecord?id=CVE-2023-31036"
                }
            ],
            "release_date": "2023-12-19T00:00:00Z",
            "scores": [
                {
                    "cvss_v3": {
                        "attackComplexity": "HIGH",
                        "attackVector": "NETWORK",
                        "availabilityImpact": "HIGH",
                        "baseScore": 7.5,
                        "baseSeverity": "HIGH",
                        "confidentialityImpact": "HIGH",
                        "integrityImpact": "HIGH",
                        "privilegesRequired": "LOW",
                        "scope": "UNCHANGED",
                        "userInteraction": "NONE",
                        "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:H/I:H/A:H",
                        "version": "3.1"
                    },
                    "products": [
                        "windows_linux_triton_inference_server_all_versions_prior_to_2_40"
                    ]
                }
            ]
        }
    ]
}